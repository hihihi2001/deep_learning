{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G-b5uAKd9TV"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17GYI0VlTaoN_Ksjk_8B3237rX8F5OkDl?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2sqfWxif5oT",
    "outputId": "97f12cc5-a5a2-495c-d8d2-6e53c113f34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperas\n",
      "  Downloading hyperas-0.4.1-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: nbformat in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperas) (5.1.3)\n",
      "Requirement already satisfied: nbconvert in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperas) (6.0.7)\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperas) (2.4.3)\n",
      "Requirement already satisfied: jupyter in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied: entrypoints in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperas) (0.3)\n",
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.6.2)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (0.18.2)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.15.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.6.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.20.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (4.59.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (2.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt->hyperas) (5.0.6)\n",
      "Requirement already satisfied: jupyter-console in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (6.4.0)\n",
      "Requirement already satisfied: qtconsole in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (5.0.3)\n",
      "Requirement already satisfied: ipykernel in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (5.3.4)\n",
      "Requirement already satisfied: notebook in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (6.3.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (7.6.3)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (6.1)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (5.0.5)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (7.22.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (6.1.12)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (3.0.17)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (2.8.1)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.17.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->hyperas) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from traitlets>=4.1.0->ipykernel->jupyter->hyperas) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->hyperas) (1.0.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (4.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (0.17.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (2.11.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (20.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->hyperas) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook->jupyter->hyperas) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook->jupyter->hyperas) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->hyperas) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->notebook->jupyter->hyperas) (1.1.1)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->hyperas) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->hyperas) (5.4.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.1.2)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.5.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->hyperas) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\programdata\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->hyperas) (1.10)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->nbconvert->hyperas) (20.9)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
      "Requirement already satisfied: qtpy in c:\\programdata\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
      "Installing collected packages: py4j, hyperopt, hyperas\n",
      "Successfully installed hyperas-0.4.1 hyperopt-0.2.7 py4j-0.10.9.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (1.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (4.59.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (1.20.1)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: py4j in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (0.10.9.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (2.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt) (5.0.6)\n"
     ]
    }
   ],
   "source": [
    "# érdemes előre telepíteni, és utána újraindítani\n",
    "!pip3 install hyperas\n",
    "!pip3 install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8WZOboK0WWXb"
   },
   "outputs": [],
   "source": [
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "uDXekaGOWiNN",
    "outputId": "1da889dd-ec96-4a3a-c24f-63f0505f19b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Plot some example images\\nimport matplotlib.pyplot as plt\\n\\ncifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\\nprint('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) \\nprint('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))\\n\\nf, axarr = plt.subplots(1, 5)\\nf.set_size_inches(16, 4)\\n\\nfor i in range(5):\\n    img = X_train[i]\\n    axarr[i].imshow(img)\\nplt.show()\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Plot some example images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) \n",
    "print('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))\n",
    "\n",
    "f, axarr = plt.subplots(1, 5)\n",
    "f.set_size_inches(16, 4)\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_train[i]\n",
    "    axarr[i].imshow(img)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tJVRUEsWWrT9"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical \n",
    "\n",
    "def data():\n",
    "  # Import the CIRAF10 dataset\n",
    "  (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "  # Transform label indices to one-hot encoded vectors\n",
    "  y_train = to_categorical(y_train, num_classes=10)\n",
    "  y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "  # Change data type\n",
    "  X_train = X_train.astype('float32')\n",
    "  X_test = X_test.astype('float32')\n",
    "\n",
    "  # Normalization of pixel values (to [0-1] range)\n",
    "  X_train /= 255\n",
    "  X_test /= 255\n",
    "  \n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e_btmIjlg8sS"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import hyperas\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "  # hyperparam space:\n",
    "  layer_size_1 = {{choice([16, 32, 64, 128, 256])}}\n",
    "  layer_size_2 = {{choice([16, 32, 64, 128, 256])}}\n",
    "  layer_size_3 = {{choice([16, 32, 64, 128, 256])}}\n",
    "  dropout_1 = {{uniform(0, 0.5)}}\n",
    "  dropout_2 = {{uniform(0, 0.5)}}\n",
    "  dropout_3 = {{uniform(0, 0.5)}}\n",
    "  activation = {{choice(['relu', 'leakyrelu', 'swish'])}}\n",
    "  learning_rate = {{uniform(0.0001, 0.001)}}\n",
    "  batch_size = {{choice([32, 128, 512])}}\n",
    "  print('hyperparams: ', layer_size_1, layer_size_2, layer_size_3, dropout_1, dropout_2, dropout_3, activation, batch_size)\n",
    "\n",
    "  # Crate model\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(layer_size_1, kernel_size=(3, 3), activation=activation, input_shape=(32,32,3,))) \n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout( dropout_1))\n",
    "  model.add(Conv2D(layer_size_2, kernel_size=(3, 3), activation=activation))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout( dropout_2))\n",
    "  model.add(Conv2D(layer_size_3, kernel_size=(3, 3), activation=activation))\n",
    "  model.add(Dropout( dropout_3))\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0006),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  # Train model\n",
    "  result = model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "                    callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)],\n",
    "                    validation_split=0.2, shuffle=True)\n",
    "  # save best val acc\n",
    "  best_val_acc = np.amax(result.history['val_accuracy']) \n",
    "  print('best val_acc:', best_val_acc)\n",
    "  \n",
    "  # Print logs and hyperparams into csv\n",
    "  with open('hyperas-ciraf10-log.csv', 'a') as csv_file:\n",
    "      csv_file.write(str(layer_size_1) + ';')\n",
    "      csv_file.write(str(layer_size_2) + ';')\n",
    "      csv_file.write(str(layer_size_2) + ';')\n",
    "      csv_file.write(str(dropout_1) + ';')\n",
    "      csv_file.write(str(dropout_2) + ';')\n",
    "      csv_file.write(str(dropout_3) + ';')\n",
    "      csv_file.write(str(activation) + ';')\n",
    "      csv_file.write(str(learning_rate) + ';')\n",
    "      csv_file.write(str(batch_size) + ';')\n",
    "      csv_file.write(str(best_val_acc) + '\\n')\n",
    "\n",
    "  return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UzH8xOmMXINj"
   },
   "outputs": [],
   "source": [
    "# log fájl inicializálás / fejléc\n",
    "with open('hyperas-ciraf10-log.csv', 'w') as csv_file:\n",
    "  csv_file.write('layer_size_1' + ';')\n",
    "  csv_file.write('layer_size_2' + ';')\n",
    "  csv_file.write('layer_size_2' + ';')\n",
    "  csv_file.write('dropout_1' + ';')\n",
    "  csv_file.write('dropout_2' + ';')\n",
    "  csv_file.write('dropout_3' + ';')\n",
    "  csv_file.write('activation' + ';')\n",
    "  csv_file.write('learning_rate' + ';')\n",
    "  csv_file.write('batch_size' + ';')\n",
    "  csv_file.write('best_val_acc' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7p_StYwOnbJp"
   },
   "outputs": [],
   "source": [
    "# ezután colab-ról le kell tölteni a notebook-ot\n",
    "# és a .ipynb fájlt utána visszatölteni az aktuális könyvtárba\n",
    "\n",
    "# erre azért van szükség, mert a hyperas a fenti kódben regexp-ekkel cseréli ki\n",
    "# a hiperparaméter változókat az adott értékekre\n",
    "\n",
    "# ha nem jupyter notebook-ban használjuk a hyperas-t, akkor nem kell ilyen trükközés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "LXi3FyAjncxy",
    "outputId": "6510f490-a412-43fe-ce3c-01ebafe1974f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import cifar10\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils.np_utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import hyperas\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'layer_size_1': hp.choice('layer_size_1', [16, 32, 64, 128, 256]),\n",
      "        'layer_size_1_1': hp.choice('layer_size_1_1', [16, 32, 64, 128, 256]),\n",
      "        'layer_size_1_2': hp.choice('layer_size_1_2', [16, 32, 64, 128, 256]),\n",
      "        'dropout_1': hp.uniform('dropout_1', 0, 0.5),\n",
      "        'dropout_1_1': hp.uniform('dropout_1_1', 0, 0.5),\n",
      "        'dropout_1_2': hp.uniform('dropout_1_2', 0, 0.5),\n",
      "        'activation': hp.choice('activation', ['relu', 'leakyrelu', 'swish']),\n",
      "        'learning_rate': hp.uniform('learning_rate', 0.0001, 0.001),\n",
      "        'batch_size': hp.choice('batch_size', [32, 128, 512]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: # Import the CIRAF10 dataset\n",
      "  3: (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
      "  4: \n",
      "  5: # Transform label indices to one-hot encoded vectors\n",
      "  6: y_train = to_categorical(y_train, num_classes=10)\n",
      "  7: y_test = to_categorical(y_test, num_classes=10)\n",
      "  8: \n",
      "  9: # Change data type\n",
      " 10: X_train = X_train.astype('float32')\n",
      " 11: X_test = X_test.astype('float32')\n",
      " 12: \n",
      " 13: # Normalization of pixel values (to [0-1] range)\n",
      " 14: X_train /= 255\n",
      " 15: X_test /= 255\n",
      " 16: \n",
      " 17: \n",
      " 18: \n",
      " 19: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:   # hyperparam space:\n",
      "   4:   layer_size_1 = space['layer_size_1']\n",
      "   5:   layer_size_2 = space['layer_size_1_1']\n",
      "   6:   layer_size_3 = space['layer_size_1_2']\n",
      "   7:   dropout_1 = space['dropout_1']\n",
      "   8:   dropout_2 = space['dropout_1_1']\n",
      "   9:   dropout_3 = space['dropout_1_2']\n",
      "  10:   activation = space['activation']\n",
      "  11:   learning_rate = space['learning_rate']\n",
      "  12:   batch_size = space['batch_size']\n",
      "  13:   print('hyperparams: ', layer_size_1, layer_size_2, layer_size_3, dropout_1, dropout_2, dropout_3, activation, batch_size)\n",
      "  14: \n",
      "  15:   # Crate model\n",
      "  16:   model = Sequential()\n",
      "  17: \n",
      "  18:   model.add(Conv2D(layer_size_1, kernel_size=(3, 3), activation=activation, input_shape=(32,32,3,))) \n",
      "  19:   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  20:   model.add(Dropout( dropout_1))\n",
      "  21:   model.add(Conv2D(layer_size_2, kernel_size=(3, 3), activation=activation))\n",
      "  22:   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  23:   model.add(Dropout( dropout_2))\n",
      "  24:   model.add(Conv2D(layer_size_3, kernel_size=(3, 3), activation=activation))\n",
      "  25:   model.add(Dropout( dropout_3))\n",
      "  26: \n",
      "  27:   model.add(Flatten())\n",
      "  28:   model.add(Dense(256, activation='relu'))\n",
      "  29:   model.add(Dense(10, activation='softmax'))\n",
      "  30: \n",
      "  31:   model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0006),\n",
      "  32:                 loss='categorical_crossentropy',\n",
      "  33:                 metrics=['accuracy'])\n",
      "  34:   \n",
      "  35:   # Train model\n",
      "  36:   result = model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
      "  37:                     callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)],\n",
      "  38:                     validation_split=0.2, shuffle=True)\n",
      "  39:   # save best val acc\n",
      "  40:   best_val_acc = np.amax(result.history['val_accuracy']) \n",
      "  41:   print('best val_acc:', best_val_acc)\n",
      "  42:   \n",
      "  43:   # Print logs and hyperparams into csv\n",
      "  44:   with open('hyperas-ciraf10-log.csv', 'a') as csv_file:\n",
      "  45:       csv_file.write(str(layer_size_1) + ';')\n",
      "  46:       csv_file.write(str(layer_size_2) + ';')\n",
      "  47:       csv_file.write(str(layer_size_2) + ';')\n",
      "  48:       csv_file.write(str(dropout_1) + ';')\n",
      "  49:       csv_file.write(str(dropout_2) + ';')\n",
      "  50:       csv_file.write(str(dropout_3) + ';')\n",
      "  51:       csv_file.write(str(activation) + ';')\n",
      "  52:       csv_file.write(str(learning_rate) + ';')\n",
      "  53:       csv_file.write(str(batch_size) + ';')\n",
      "  54:       csv_file.write(str(best_val_acc) + '\\n')\n",
      "  55: \n",
      "  56:   return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}\n",
      "  57: \n",
      "  0%|                                                                            | 0/5 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.random.mtrand.RandomState' object has no attribute 'integers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e89e7490fd79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# teljes hiperparaméter optimalizálás indítása\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m best_run, best_model = optim.minimize(model=create_model,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                           \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_space\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpair\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \"\"\"\n\u001b[1;32m---> 59\u001b[1;33m     best_run, space = base_minimizer(model=model,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                      \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                                      \u001b[0mfunctions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     return (\n\u001b[1;32m--> 133\u001b[1;33m         fmin(keras_fmin_fnct,\n\u001b[0m\u001b[0;32m    134\u001b[0m              \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m              \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fmin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         return trials.fmin(\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         return fmin(\n\u001b[0m\u001b[0;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[1;31m# processes orchestration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                     new_trials = algo(\n\u001b[1;32m--> 279\u001b[1;33m                         \u001b[0mnew_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m31\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m                     )\n\u001b[0;32m    281\u001b[0m                     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.random.mtrand.RandomState' object has no attribute 'integers'"
     ]
    }
   ],
   "source": [
    "# teljes hiperparaméter optimalizálás indítása\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          notebook_name='DL_kishf5',\n",
    "                                          trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXYoxfEkYn1H",
    "outputId": "88b004a7-5515-402f-f2f6-8ac3e029dc30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[0.8043055534362793, 0.734000027179718]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29AINckAZGSA",
    "outputId": "cf556b2a-f0d3-47a7-905b-b71c69ab3c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 620,362\n",
      "Trainable params: 620,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_kishf5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
